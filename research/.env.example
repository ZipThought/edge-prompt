# EdgePrompt Research Environment Configuration Example (Phase 1)
# Copy this file to .env and update with your values

# LM Studio API URL (required for EdgeLLM models using LM Studio)
# This is the URL where the LM Studio server is running
LM_STUDIO_URL=http://localhost:1234

# Ollama API URL (required for EdgeLLM models using Ollama)
# This is the URL where the Ollama server is running
OLLAMA_URL=http://localhost:11434

# OpenAI API Key (required for CloudLLM models using OpenAI)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# Anthropic API Key (required for CloudLLM models using Anthropic)
# Get your API key from: https://console.anthropic.com/settings/keys
ANTHROPIC_API_KEY=sk-ant-api03-...

# Google AI API Key (optional - uncomment if using Google models)
# GOOGLE_API_KEY=...

# Optional: Mock Mode configuration (overrides command-line flag)
# Set to "true" to use mock models instead of real LLMs
# MOCK_MODE=false